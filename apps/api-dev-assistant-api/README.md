# API Development Assistant - gRPC Microservice

A gRPC-based microservice that provides AI-powered API development assistance using LangChain, LangGraph, and MCP (Model Context Protocol) tools.

## Features

- ğŸš€ **gRPC Streaming**: Server-side streaming for real-time chat responses
- ğŸ¤– **LangChain Agent**: Intelligent agent with tool-calling capabilities
- ğŸ”§ **MCP Integration**: Connect to Model Context Protocol servers for extended functionality
- ğŸ’¾ **Redis Checkpointing**: Persistent conversation history with Redis
- ğŸ”„ **Streaming Support**: Real-time token streaming for responsive UX
- ğŸ“Š **Token Usage Tracking**: Monitor and report token consumption
- ğŸ¯ **Type-Safe**: Full TypeScript support with generated proto types

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  gRPC Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ StreamChat / DeleteConversation
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ChatController (gRPC)           â”‚
â”‚  - Pattern matching with ts-pattern â”‚
â”‚  - Event streaming                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AgentService                 â”‚
â”‚  - LangGraph agent                  â”‚
â”‚  - Streaming orchestration          â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      â”‚
      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP Client  â”‚      â”‚    Redis     â”‚
â”‚  Service    â”‚      â”‚ Checkpointer â”‚
â”‚             â”‚      â”‚              â”‚
â”‚ - Tool mgmt â”‚      â”‚ - State mgmt â”‚
â”‚ - LangChain â”‚      â”‚ - History    â”‚
â”‚   tools     â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Setup

### Prerequisites

- Node.js 18+
- Redis server running
- Mistral AI API key
- MCP servers (optional, for extended tools)

### Installation

1. Install dependencies (already done at workspace level):
```bash
npm install
```

2. Generate proto types:
```bash
npm run proto:generate
```

3. Configure environment:
```bash
cp apps/api-dev-assistant-api/.env.example apps/api-dev-assistant-api/.env
# Edit .env with your configuration
```

### Configuration

#### Redis Setup

Start Redis using the provided docker-compose:
```bash
cd iac
docker-compose -f docker-compose.redis.yml up -d
```

Or use existing Redis:
```bash
# In .env
REDIS_URL=redis://localhost:6379
```

#### Mistral AI Configuration

Get your API key from [Mistral AI](https://console.mistral.ai/):

```bash
# In .env
MISTRAL_API_KEY=your_api_key_here
MODEL_NAME=mistral-large-latest
MODEL_TEMPERATURE=0.7
```

#### MCP Servers Configuration

Configure MCP servers in `.env` as a JSON array:
```bash
MCP_SERVERS_CONFIG=[
  {
    "name": "filesystem",
    "command": "npx",
    "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/workspace"]
  },
  {
    "name": "sqlite",
    "command": "uvx",
    "args": ["mcp-server-sqlite", "--db-path", "/path/to/db.sqlite"]
  }
]
```

## Running

### Development
```bash
npm run api-dev-assistant-api:dev
```

### Production Build
```bash
npm run api-dev-assistant-api:build
node dist/apps/api-dev-assistant-api/main.js
```

## Protocol

### gRPC Service Definition

```protobuf
service ChatService {
  rpc StreamChat (ChatRequest) returns (stream ChatChunk);
  rpc DeleteConversation (DeleteRequest) returns (DeleteResponse);
}
```

### StreamChat

Server-side streaming RPC that returns chunks of:
- **Text**: Incremental assistant responses
- **Tool Calls**: When the agent invokes MCP tools
- **Tool Results**: Results from tool execution
- **Metadata**: Final metadata with token usage
- **Errors**: Any errors during processing

### Message Flow

```
Client Request
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChatRequest   â”‚
â”‚  - conv_id     â”‚
â”‚  - message     â”‚
â”‚  - metadata    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Processing        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. Load history     â”‚ â”‚
â”‚  â”‚ 2. Add user message â”‚ â”‚
â”‚  â”‚ 3. LLM inference    â”‚ â”‚
â”‚  â”‚ 4. Tool calls?      â”‚ â”‚
â”‚  â”‚ 5. Execute tools    â”‚ â”‚
â”‚  â”‚ 6. Final response   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ (streaming)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChatChunk #1    â”‚ â†’ Text chunk
â”‚  ChatChunk #2    â”‚ â†’ Tool call
â”‚  ChatChunk #3    â”‚ â†’ Tool result
â”‚  ChatChunk #4    â”‚ â†’ Text chunk
â”‚  ChatChunk #N    â”‚ â†’ Metadata (final)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
apps/api-dev-assistant-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â””â”€â”€ chat.controller.ts      # gRPC controller
â”‚   â”‚   â”œâ”€â”€ langchain/
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.service.ts        # LangGraph agent
â”‚   â”‚   â”‚   â”œâ”€â”€ redis-checkpointer.ts   # Redis state mgmt
â”‚   â”‚   â”‚   â””â”€â”€ redis.service.ts        # Redis connection
â”‚   â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”‚   â””â”€â”€ mcp-client.service.ts   # MCP integration
â”‚   â”‚   â””â”€â”€ app.module.ts               # Main module
â”‚   â”œâ”€â”€ generated/
â”‚   â”‚   â””â”€â”€ chat.ts                     # Generated proto types
â”‚   â””â”€â”€ main.ts                         # gRPC server bootstrap
â”œâ”€â”€ .env.example                        # Environment template
â””â”€â”€ README.md
```

## Development

### Regenerate Proto Types
```bash
npm run proto:generate
```

### Testing the Service

Use a gRPC client like [grpcurl](https://github.com/fullstorydev/grpcurl) or [BloomRPC](https://github.com/bloomrpc/bloomrpc):

```bash
# List services
grpcurl -plaintext localhost:50051 list

# Stream chat
grpcurl -plaintext -d '{
  "conversation_id": "test-conv-1",
  "message": "Hello, can you help me create an API?"
}' localhost:50051 chat.ChatService/StreamChat
```

## Key Technologies

- **NestJS**: Framework for building scalable Node.js applications
- **gRPC**: High-performance RPC framework
- **LangChain**: Framework for building LLM applications
- **LangGraph**: Graph-based agent orchestration
- **MCP**: Model Context Protocol for tool integration
- **Redis**: In-memory data store for state management
- **ts-pattern**: Pattern matching for TypeScript
- **ts-proto**: Protocol buffers code generation

## Next Steps

1. **Client Implementation**: Build a gRPC client (Angular, React, etc.)
2. **Additional Tools**: Add more MCP servers for extended capabilities
3. **Monitoring**: Add metrics and observability
4. **Authentication**: Implement auth/authorization
5. **Rate Limiting**: Add rate limiting and quota management
6. **Deployment**: Containerize and deploy to cloud

## License

MIT
